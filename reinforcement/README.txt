Kenneth Chuson 
921030302

Brief Description: 

First of all, that I have to read the requirement files such as mdp.py, learningAgents.py, and etc. The value iteration problem, provided us the formula of Vk + 1 and I have to implement 3 functions which are the computeActionFromValues(state) and computeQValuesFromValues(state, action), then I have to implement the run iteration function to compute a policy. 
The bridge crossing analysis problem reminds me the concept of deterministic, so which the answer discount is higher which is 0.9 
problem 3, takes the most of my time because there is a lot of math involve to determine between the exit and the cliff. So, either risking or avoiding and determine what discount, noise, and living reward would be like. 
Question 6 also takes most of my time for doing this implementation of q learning, but the comments provided us in this assignments helps me where, how, and what should I implement each of the functions. The q learning helps the agent to calculate the learn from their experience. 
Question 7, this is a randomize using a flip coin function which is 50 50 chance of probability of every iterations. 
After that, it is not possible when we try the same experiment with an epsilon of 0. 
The final problem, which we need to implement the approximate Q agent which takes the approximation Q function which are Q(s, a) and the difference that uses the identity extractor. 



How many hours did you spend on this assignment? 

I spent around 11 hours total in this assignment
